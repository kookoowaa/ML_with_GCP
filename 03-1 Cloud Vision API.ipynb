{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Cloud Vision API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사용하기에 앞서 Cloud Vision API 활성화와 클라이언트 생성을 선행\n",
    "- 활성화는 console에서 API 사용 설정 가능\n",
    "- 클라이언트는 `google.cloud.vision`을 통해 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- client 인스턴스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> ## 레이블 검출하기\n",
    "#### 이미지 지정하고 API 호출하기\n",
    "- API에 이미지를 전송하려면 로컬 파일을 인코딩해서 요청 매개변수를 포함시키거나, 파일 경로를 지정해야 함\n",
    "- 라이브러리를 사용하면 별도의 처리를 따로 하지 않아도 됨\n",
    "- **아래는 로컬파일 또는 GCS 사용 시 API 호출하는 방법임**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local 파일 사용 시\n",
    "import io\n",
    "with io.open('gcpml-book/Part1/seagull.jpg', 'rb') as image_file:\n",
    "  content = image_file.read()\n",
    "\n",
    "image = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS 사용시\n",
    "image = types.Image()\n",
    "image.source.image_uri = 'gcpml-book/Part1/seagull.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 레이블 검출하고 실행하기\n",
    "- `client`객체에 `label_detection`메서드를 호출하면 API에 요청\n",
    "- 성공 시 레이블 정보가 리스트로 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래와 같이 API에 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.label_detection(image = image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반환된 객체에 label_annotations를 보면 다양한 정보가 포함되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mid: \"/m/015p6\"\n",
       "description: \"bird\"\n",
       "score: 0.9799333214759827\n",
       "topicality: 0.9799333214759827"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = response.label_annotations\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for문을 사용하여 중요 정보를 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "Score: 0.98, Label: bird\n",
      "Score: 0.94, Label: water\n",
      "Score: 0.92, Label: seabird\n",
      "Score: 0.88, Label: beak\n",
      "Score: 0.87, Label: fauna\n",
      "Score: 0.84, Label: gull\n",
      "Score: 0.72, Label: water bird\n",
      "Score: 0.72, Label: charadriiformes\n",
      "Score: 0.65, Label: european herring gull\n",
      "Score: 0.51, Label: feather\n"
     ]
    }
   ],
   "source": [
    "print ('Labels:')\n",
    "\n",
    "for i in labels:\n",
    "  print('Score: {}, Label: {}'.format(round(i.score, 2), i.description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 얼굴 검출하기\n",
    "\n",
    "- 이전과 마찬가지로 클라이언트를 만들고 이미지를 읽어와서 `image` 객체를 생성\n",
    "- 이번에는 `face_detection`을 통해 API를 요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open('gcpml-book/Part1/face.jpg', 'rb') as image_file:\n",
    "  content = image_file.read()\n",
    "image = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.face_detection(image=image)\n",
    "face = response.face_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반환된 결과는 얼굴 주요부위의 좌표, 감정, 특징 등의 정보가 포함되어 있음\n",
    "```\n",
    "face[0]\n",
    ">bounding_poly {\n",
    ">  vertices {\n",
    ">    x: 512\n",
    ">    y: 260\n",
    ">  }\n",
    ">  vertices {\n",
    ">    x: 671\n",
    ">    y: 260\n",
    ">  }\n",
    ">  vertices {\n",
    ">    x: 671\n",
    ">    y: 445\n",
    ">  }\n",
    ">  vertices {\n",
    ">    x: 512\n",
    ">    y: 445\n",
    ">  }\n",
    ">}\n",
    ">.\n",
    ">.\n",
    ">.\n",
    ">under_exposed_likelihood: VERY_UNLIKELY\n",
    ">blurred_likelihood: VERY_UNLIKELY\n",
    ">headwear_likelihood: VERY_UNLIKELY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감정은 카테고리 값(int)를 출력하기에 이에 대응하는 튜플 생성 선행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face[0].joy_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first face demonstrates \"Very_likely joy\"\n"
     ]
    }
   ],
   "source": [
    "likelihood_lists = ['Unknown', 'Very_unlikely', 'Unlikely', 'Possible', 'Likely', 'Very_likely']\n",
    "print('first face demonstrates \"{} joy\"'.format(likelihood_lists[face[0].joy_likelihood]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검출된 얼굴들의 감정을 모두 출력하자면 다음과 같이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face1 ==================\n",
      "JOY: Very_likely\n",
      "ANGER: Very_unlikely\n",
      "SORROW: Very_unlikely\n",
      "SURPRISE: Very_unlikely\n",
      "\n",
      "face2 ==================\n",
      "JOY: Very_likely\n",
      "ANGER: Very_unlikely\n",
      "SORROW: Very_unlikely\n",
      "SURPRISE: Very_unlikely\n",
      "\n",
      "face3 ==================\n",
      "JOY: Very_likely\n",
      "ANGER: Very_unlikely\n",
      "SORROW: Very_unlikely\n",
      "SURPRISE: Very_unlikely\n",
      "\n",
      "face4 ==================\n",
      "JOY: Very_likely\n",
      "ANGER: Very_unlikely\n",
      "SORROW: Very_unlikely\n",
      "SURPRISE: Very_unlikely\n",
      "\n",
      "face5 ==================\n",
      "JOY: Possible\n",
      "ANGER: Very_unlikely\n",
      "SORROW: Very_unlikely\n",
      "SURPRISE: Very_unlikely\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(face)):\n",
    "  print('face'+str(i+1)+' '+'='*18)\n",
    "  print('JOY: '+ likelihood_lists[face[i].joy_likelihood])\n",
    "  print('ANGER: '+ likelihood_lists[face[i].anger_likelihood])\n",
    "  print('SORROW: '+ likelihood_lists[face[i].sorrow_likelihood])\n",
    "  print('SURPRISE: '+ likelihood_lists[face[i].surprise_likelihood]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
