{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Cloud Natural Language API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "> ## 엔티티 분석\n",
    "\n",
    "- 엔티티 분석이란 텍스트에 포함되어 있는 엔티티(사람이름, 고유명사 등) 정보를 분석하는 기능\n",
    "- 클라이언트 인스턴스를 만드는 것은 앞의 다른 예제와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "\n",
    "nl_client = language.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분석은 `analyze_entities` 함수를 호출하여 수행\n",
    "- text, html, 혹은 GCS 경로를 지정할 수 있음\n",
    "- 다만, 현재 굉장히 빠르게 바뀌고 있는 API로, 필요 시 https://google-cloud-python.readthedocs.io/en/latest/language/usage.html 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entities {\n",
       "  name: \"\\354\\204\\234\\354\\232\\270\"\n",
       "  type: LOCATION\n",
       "  metadata {\n",
       "    key: \"mid\"\n",
       "    value: \"/m/0hsqf\"\n",
       "  }\n",
       "  metadata {\n",
       "    key: \"wikipedia_url\"\n",
       "    value: \"https://en.wikipedia.org/wiki/Seoul\"\n",
       "  }\n",
       "  salience: 0.2728408873081207\n",
       "  mentions {\n",
       "    text {\n",
       "      content: \"\\354\\204\\234\\354\\232\\270\"\n",
       "    }\n",
       "    type: PROPER\n",
       "  }\n",
       "}\n",
       "entities {\n",
       "  name: \"\\352\\265\\254\\353\\246\\204\"\n",
       "  type: OTHER\n",
       "  salience: 0.18909965455532074\n",
       "  mentions {\n",
       "    text {\n",
       "      content: \"\\352\\265\\254\\353\\246\\204\"\n",
       "      begin_offset: 21\n",
       "    }\n",
       "    type: COMMON\n",
       "  }\n",
       "}\n",
       "entities {\n",
       "  name: \"\\352\\260\\225\\354\\225\\204\\354\\247\\200\"\n",
       "  type: PERSON\n",
       "  salience: 0.1854119598865509\n",
       "  mentions {\n",
       "    text {\n",
       "      content: \"\\352\\260\\225\\354\\225\\204\\354\\247\\200\"\n",
       "      begin_offset: 12\n",
       "    }\n",
       "    type: COMMON\n",
       "  }\n",
       "}\n",
       "entities {\n",
       "  name: \"\\354\\247\\221\"\n",
       "  type: LOCATION\n",
       "  salience: 0.18053360283374786\n",
       "  mentions {\n",
       "    text {\n",
       "      content: \"\\354\\247\\221\"\n",
       "      begin_offset: 10\n",
       "    }\n",
       "    type: COMMON\n",
       "  }\n",
       "}\n",
       "entities {\n",
       "  name: \"\\354\\235\\264\\353\\246\\204\"\n",
       "  type: OTHER\n",
       "  salience: 0.17211389541625977\n",
       "  mentions {\n",
       "    text {\n",
       "      content: \"\\354\\235\\264\\353\\246\\204\"\n",
       "      begin_offset: 17\n",
       "    }\n",
       "    type: COMMON\n",
       "  }\n",
       "}\n",
       "language: \"ko\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분석할 문장\n",
    "text = '서울에 사는 우리 집 강아지의 이름은 구름이입니다'\n",
    "document = language.types.Document(content=text,\n",
    "                                  language = 'ko',\n",
    "                                  type = 'PLAIN_TEXT')\n",
    "\n",
    "# 엔티티 분석\n",
    "response = nl_client.analyze_entities(document =document,\n",
    "                                     encoding_type = 'UTF32')\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `response.entities`는 다음과 같은 결과 값 보유  \n",
    "    name: 명칭  \n",
    "    entity_type: 엔티티의 종류(PERSON, LOCATION, ORGANIZATIONS...)  \n",
    "    metadata: Wikipedia 혹은 Knowledge Graph의 MID가 들어 있음  \n",
    "    salience: 중요도, 특징성을 의미\n",
    "- 이를 정리하면 아래와 같이 결과 값 출력 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1====================\n",
      "단어: 서울\n",
      "종류: Location\n",
      "메타데이터: https://en.wikipedia.org/wiki/Seoul\n",
      "중요도: 0.2728408873081207\n",
      "2====================\n",
      "단어: 구름\n",
      "종류: Other\n",
      "메타데이터: None\n",
      "중요도: 0.18909965455532074\n",
      "3====================\n",
      "단어: 강아지\n",
      "종류: Person\n",
      "메타데이터: None\n",
      "중요도: 0.1854119598865509\n",
      "4====================\n",
      "단어: 집\n",
      "종류: Location\n",
      "메타데이터: None\n",
      "중요도: 0.18053360283374786\n",
      "5====================\n",
      "단어: 이름\n",
      "종류: Other\n",
      "메타데이터: None\n",
      "중요도: 0.17211389541625977\n"
     ]
    }
   ],
   "source": [
    "# 타입을 나타내는 튜플 정의\n",
    "entity_type = ['Unknown', 'Person', 'Location', 'Organization', 'Event', 'Work_of_Art', 'Consumer_Good', 'Other']\n",
    "\n",
    "# 결과 출력\n",
    "n=1\n",
    "for entity in response.entities:\n",
    "  print(str(n)+'='*20)\n",
    "  print('단어: {}'.format(entity.name))\n",
    "  print('종류: {}'.format(entity_type[entity.type]))\n",
    "  print('메타데이터: {}'.format(entity.metadata.get('wikipedia_url')))\n",
    "  print('중요도: {}'.format(entity.salience))\n",
    "  n+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
